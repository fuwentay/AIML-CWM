{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "**Expectation:** find solution to MSE regression using GD, Line search, GD with Momentum and 2nd Order Method, and gradient free methods.\n"
      ],
      "metadata": {
        "id": "KF3EC4bjh9GZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "3AdxAZQ5EcKK",
        "outputId": "5edaf7c5-98ca-4196-8bbd-bf08127ccdef"
      },
      "source": [
        "#Linear Regression for general functions\n",
        "import numpy as np\n",
        "import numpy.linalg as la\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "pi=math.pi\n",
        "\n",
        "data_set_size = 20\n",
        "noise_level = 0.3\n",
        "\n",
        "# generate 20 numbers from -1 to 1 with equal stepsize\n",
        "x=np.linspace(-1,1,data_set_size)\n",
        "\n",
        "# generate training target (noise contaminated!)\n",
        "y=np.sin(2*pi*.5*x)+noise_level*np.random.randn(x.size)\n",
        "\n",
        "# plot the training data points\n",
        "plt.plot(x, y, 'ro')\n",
        "\n",
        "# plot the true function\n",
        "plt.plot(np.linspace(-1,1,50), np.sin(2*pi*.5*np.linspace(-1,1,50)), 'black')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5a40f81600>]"
            ]
          },
          "metadata": {},
          "execution_count": 320
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = x.shape[0]\n",
        "M = 10\n",
        "d = M+1 # dimnesionality\n",
        "X = []\n",
        "for i in range(M+1):\n",
        "  X.append(x**i)\n",
        "\n",
        "X = np.array(X).T\n",
        "\n",
        "print('x',X.shape)\n",
        "print('y',y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OD4J4UE9y_V",
        "outputId": "c3a51ee0-6ee4-4818-c644-e01890edb7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x (20, 11)\n",
            "y (20,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In previous class we found w $\\mathbf{w}$ using the closed form solution, today we first find $\\mathbf{w}$ using Gradient Decent (GD). *Note for this toy example the is no reason to use a iterative optimiser, as the exact method exsist but it makes for a nice test bed.*\n",
        "\n",
        "The Mean Squared Loss / Mean Squared Error (MSE) can be written as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "  L(\\mathbf{w}) = \\frac{1}{N}\\sum_{n=1}^N(\\sum_{i=1}^{d+1} x_{n,i} \\cdot w_i - y_n)^2\n",
        "\\end{equation}\n",
        "\n",
        "Or writen with matrices:\n",
        "\n",
        "\\begin{equation}\n",
        "  L(\\mathbf{w}) = \\frac{1}{N} ||X\\mathbf{w} - \\mathbf{y}||_2^2 = \\frac{1}{N} (X\\mathbf{w} - \\mathbf{y})^\\top(X\\mathbf{w} - \\mathbf{y})\n",
        "\\end{equation}\n",
        "\n",
        "**Question 1** Derive the gradeint of the MSE. Write you awnser here in latex:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\nabla_\\mathbf{w} L(\\mathbf{w}) =\n",
        "\\end{equation}\n",
        "\n",
        "We then use the following update:"
      ],
      "metadata": {
        "id": "7N72iZaC8P1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2** prove that $L$ is convex in $\\mathbf{w}$ (*hint think about the Hessain*)\n",
        "\n",
        "Write you awnser here in latex:\n"
      ],
      "metadata": {
        "id": "4Reukn_KQ2o1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Descent**"
      ],
      "metadata": {
        "id": "zrMBPRARXCqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will first optimise $L(\\mathbf{w})$ using Gradient Descent.\n",
        "\n",
        "Which uses the following update:\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "  \\mathbf{w}_{t+1} = \\mathbf{w}_t - \\eta_t \\nabla_\\mathbf{w} L(\\mathbf{w})\n",
        "\\end{equation}\n"
      ],
      "metadata": {
        "id": "Ga5Sto67Q631"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3** complete the functions below to calcuate the loss and gradients for a given $X$, $\\mathbf{y}$ & $\\mathbf{w}$."
      ],
      "metadata": {
        "id": "f7t2APpfSon6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# It useful to first write a function that calculates the loss we will use this to measure our progress\n",
        "\n",
        "def MSE_loss(X, y, w):\n",
        "  mean_loss = 0 # your code here\n",
        "  return mean_loss\n"
      ],
      "metadata": {
        "id": "96FMG1cqNgHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a quick sanity check for your loss function, If this cell throws and error your loss function still needs work!\n",
        "assert MSE_loss(np.array([0]), np.array([0]), np.array([0])) == 0\n",
        "assert MSE_loss(np.array([1]), np.array([1]), np.array([1])) == 0\n",
        "assert MSE_loss(np.array([1]), np.array([1]), np.array([0])) == 1\n",
        "assert MSE_loss(np.array([1]), np.array([0]), np.array([1])) == 1"
      ],
      "metadata": {
        "id": "E_4zQyYNxyxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It is also useful to have a function that calculate gradient at a given point\n",
        "def grad_func(x, y, w):\n",
        "  n = x.shape[0]\n",
        "  gradient = 0\n",
        "  return gradient"
      ],
      "metadata": {
        "id": "eYP6g_gd1GJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a quick sanity check for your gradient function, If this cell throws and error your gradient fucntion still needs work!\n",
        "assert la.norm(grad(np.array([[0,0],[0,0]]), np.zeros((2,1)), np.ones((2,1)))) == 0\n",
        "assert la.norm(grad(np.array([[1,0],[0,0]]), np.zeros((2,1)), np.ones((2,1)))) == 1\n",
        "assert la.norm(grad(np.array([[4,3],[4,3]]), np.zeros((2,1)), np.ones((2,1)))) == 70"
      ],
      "metadata": {
        "id": "lox8KuXj1R9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4** Implement GD and run for 1000 steps. Save the loss value after each step in the list 'gd_losses'."
      ],
      "metadata": {
        "id": "X6Qzt3E1TVMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to use an iterative optimisation method we need an initial guess:\n",
        "\n",
        "w = np.zeros(M+1)\n",
        "\n",
        "gd_losses = []\n",
        "gd_losses.append(MSE_loss(X, y, w))\n",
        "\n",
        "# ... and a step size\n",
        "\n",
        "eta = 1e-2\n",
        "\n",
        "number_of_iteratons = 1000\n",
        "\n",
        "for iter in range(number_of_iteratons):\n",
        "  # ----------------------------\n",
        "  # Your code here\n",
        "\n",
        "\n",
        "  # ----------------------------\n",
        "  loss = MSE_loss(X, y, w)\n",
        "  gd_losses.append(loss)\n",
        "  if iter % 100 == 99:\n",
        "    print(loss)\n",
        "\n",
        "plt.plot(np.arange(len(gd_losses)),gd_losses, 'red')"
      ],
      "metadata": {
        "id": "ZpgBiWOU9y6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5** Experiment different powers of ten for the step sizes $\\eta$, empically what value is the largest for which you get good performance? What does this suggest about the smoothness of $L(\\mathbf{w})$?"
      ],
      "metadata": {
        "id": "LJ4JlD8ETvBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Descent with Backtracing Line Search**"
      ],
      "metadata": {
        "id": "Ymllv-NHabMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now optimise L using GD however we will use a line search method to select $\\eta$ at each update according to the Armijo-Goldstein Condition with hyperparameter c.\n",
        "\n",
        "\\begin{align*}\n",
        "f(\\mathbf{w} - \\eta_{t,k}\\nabla f(\\mathbf{w})) \\leq f(\\mathbf{w}) - c \\eta_{t,k} \\| \\nabla f(\\mathbf{w})\\|^2,\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "e7qv-5xgXKUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_armijo_goldstein_condtions(grad, loss, trail_point_loss, eta, c):\n",
        "  grad_norm = np.linalg.norm(grad)\n",
        "  if trail_point_loss <= loss - c * eta * grad_norm:\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "metadata": {
        "id": "D7kHiI67eBED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run the backtracking line search we first select a trial point $\\mathbf{w}'$,  according to $\\mathbf{w}_0' = \\mathbf{w}_t - \\eta_{t,0} \\nabla f$ where $\\eta_0 = \\gamma$. If a trial point satisfies the acceptance condition, we set $\\mathbf{w}_t = \\mathbf{w}_t'$, otherwise  $\\eta_{t,k+1} = \\alpha \\eta_{t,k}$. And select the next trail point according to $\\mathbf{w}_t' = \\mathbf{w}_t - \\eta_{t,k} \\nabla f$."
      ],
      "metadata": {
        "id": "norn1t7uiQE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6** Implement GD with backtracking line search and run if for 1000 steps, save the loss value after each step in the list 'line_search_losses'."
      ],
      "metadata": {
        "id": "CiFHqNdRNW31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.zeros(M+1)\n",
        "\n",
        "line_search_losses = []\n",
        "line_search_losses.append(MSE_loss(X, y, w))\n",
        "\n",
        "c = 0.001\n",
        "gamma = 10\n",
        "alpha = 0.8\n",
        "max_k = 50 # make number of line search steps\n",
        "\n",
        "number_of_iteratons = 1000\n",
        "loss = MSE_loss(X, y, w)\n",
        "\n",
        "for iter in range(number_of_iteratons):\n",
        "  # ----------------------------\n",
        "  # Your code here\n",
        "\n",
        "\n",
        "  # once we have found a point that satisfies the condition we take a step using this step size\n",
        "  # ----------------------------\n",
        "  w -= eta * grad\n",
        "  eta = gamma # set eta back to its intial value\n",
        "  loss = MSE_loss(X, y, w)\n",
        "  line_search_losses.append(loss)\n",
        "\n",
        "  if iter % 100 == 99:\n",
        "    print(loss)\n",
        "\n",
        "\n",
        "plt.plot(np.arange(len(gd_losses)),gd_losses, 'red')\n",
        "plt.plot(np.arange(len(line_search_losses)),line_search_losses, 'green')"
      ],
      "metadata": {
        "id": "i0y8jt69iOPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Descent with Momentum**\n",
        "\n",
        "\\begin{align*}\n",
        "\\mathbf{m}_{0} &= 0,\\\\\n",
        "\\mathbf{m}_{t+1} &= \\mu \\mathbf{m}_{t} - \\eta_t \\nabla f(\\mathbf{w}_t),\\\\\n",
        "\\mathbf{w}_{t+1} &= \\mathbf{w}_{t} + \\mathbf{m}_{t+1}.\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "6PXvg4YTiDqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7** Implement GD with momentum for 1000 steps, save the loss value after each step in the list 'gd_with_momenutm_losses'. What do you notice when compairing against GD without Momentum?"
      ],
      "metadata": {
        "id": "AToYbDOehJQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.zeros(M+1)\n",
        "momentum = np.zeros(M+1)\n",
        "\n",
        "gd_with_momenutm_losses = []\n",
        "gd_with_momenutm_losses.append(MSE_loss(X, y, w))\n",
        "\n",
        "# ... and a step size\n",
        "\n",
        "eta = 1e-2\n",
        "mu = 0.9\n",
        "\n",
        "number_of_iteratons = 1000\n",
        "\n",
        "for iter in range(number_of_iteratons):\n",
        "  # ----------------------------\n",
        "  # Your code here\n",
        "\n",
        "  # ----------------------------\n",
        "  loss = MSE_loss(X, y, w)\n",
        "  gd_with_momenutm_losses.append(loss)\n",
        "  if iter % 100 == 99:\n",
        "    print(loss)\n",
        "\n",
        "plt.plot(np.arange(len(gd_losses)),gd_losses, 'red', label='gd')\n",
        "plt.plot(np.arange(len(line_search_losses)),line_search_losses, 'green')\n",
        "plt.plot(np.arange(len(gd_with_momenutm_losses)),gd_with_momenutm_losses, 'blue', label='gd_with_momentum')"
      ],
      "metadata": {
        "id": "xiJuaBkuWxgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Descent with Nesterov Momentum**\n",
        "\n",
        "\n",
        "\\begin{align*}\n",
        "\\mathbf{m}_{0} &= 0,\\\\\n",
        "\\mathbf{m}_{t+1} &= \\mu \\mathbf{m}_{t} - \\eta \\nabla f(\\mathbf{w}_t + \\mu \\mathbf{m}_{t}),\\\\\n",
        "\\mathbf{w}_{t+1} &= \\mathbf{w}_{t} + \\mathbf{m}_{t+1}.\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "jUcqieLHhFhI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**###Optional### Question 8** Implement GD with nesterov momentum for 1000 steps, save the loss value after each step in the list 'gd_with_momenutm_losses'."
      ],
      "metadata": {
        "id": "dMc7dLQ-hjbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.zeros(M+1)\n",
        "momentum = np.zeros(M+1)\n",
        "\n",
        "gd_with_nesterov_momenutm = []\n",
        "gd_with_nesterov_momenutm.append(MSE_loss(X, y, w))\n",
        "\n",
        "# ... and a step size\n",
        "\n",
        "eta = 1e-2\n",
        "mu = 0.9\n",
        "\n",
        "number_of_iteratons = 1000\n",
        "\n",
        "for iter in range(number_of_iteratons):\n",
        "  # ----------------------------\n",
        "  # Your code here\n",
        "\n",
        "  # ----------------------------\n",
        "  loss = MSE_loss(X, y, w)\n",
        "  gd_with_nesterov_momenutm.append(loss)\n",
        "  if iter % 100 == 99:\n",
        "    print(loss)\n",
        "\n",
        "plt.plot(np.arange(len(gd_losses)),gd_losses, 'red', label='gd')\n",
        "plt.plot(np.arange(len(line_search_losses)),line_search_losses, 'green')\n",
        "plt.plot(np.arange(len(gd_with_momenutm_losses)),gd_with_momenutm_losses, 'blue', label='gd_with_momentum')\n",
        "plt.plot(np.arange(len(gd_with_nesterov_momenutm)),gd_with_nesterov_momenutm, 'yellow', label='gd_with_momentum')"
      ],
      "metadata": {
        "id": "URsUBEAzhEZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exact Second Order**\n",
        "\n",
        "\\begin{align*}\n",
        "\\mathbf{w}_{t+1} = \\mathbf{w}_{t} -{H}_f^{-1}\\nabla f(\\mathbf{w}_t).\n",
        "\\end{align*}\n",
        "\n",
        "Where ${H}_f$ is the hessain."
      ],
      "metadata": {
        "id": "a67ahJjKpfRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 9** Implement the exact second order optimiser 1000 steps, save the loss value after each step in the list 'second_order_losses'."
      ],
      "metadata": {
        "id": "8PMXHEvLwOj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.zeros(M+1)\n",
        "\n",
        "second_order_losses = []\n",
        "second_order_losses.append(MSE_loss(X, y, w))\n",
        "\n",
        "# ... note here we don't need learning rate\n",
        "\n",
        "number_of_iteratons = 1000\n",
        "\n",
        "for iter in range(number_of_iteratons):\n",
        "  # ----------------------------\n",
        "  # Your code here\n",
        "\n",
        "  # ----------------------------\n",
        "  loss = MSE_loss(X, y, w)\n",
        "  second_order_losses.append(loss)\n",
        "  if iter % 100 == 99:\n",
        "    print(loss)\n",
        "\n",
        "plt.plot(np.arange(len(second_order_losses)),second_order_losses, 'black')\n",
        "plt.plot(np.arange(len(gd_losses)),gd_losses, 'red', label='gd')\n",
        "plt.plot(np.arange(len(line_search_losses)),line_search_losses, 'green')\n",
        "plt.plot(np.arange(len(gd_with_momenutm_losses)),gd_with_momenutm_losses, 'blue', label='gd_with_momentum')\n",
        "plt.plot(np.arange(len(gd_with_nesterov_momenutm)),gd_with_nesterov_momenutm, 'yellow', label='gd_with_momentum')"
      ],
      "metadata": {
        "id": "tmBAVHmnwZNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Question 10** Try adjusting the learning rates, which optimier is quickest? How many steps does it take to converge? Why is this? Which is the second quickest?\n",
        "\n"
      ],
      "metadata": {
        "id": "LdWHf30My0N6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reading** - Gradient Free Optimiation\n",
        "\n"
      ],
      "metadata": {
        "id": "dWBtM5rozJ2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Free Coodinate Descent\n",
        "\n",
        "Gradient free optimisers are useful when the gradient can't easily be calculated. Instead of using the gradient they only use loss values. They start by picking a candidate direction $\\mathbf{p}_t$ and then evalulating the loss in the direction of $\\mathbf{p}_t$.\n",
        "\n",
        "\n",
        "In this assignment you will code up the three point alogruthm that selects the next point according to:\n",
        "\n",
        "\\begin{equation}\n",
        "\\mathbf{w}_{t+1} = \\text{argmin}\\{ f(\\mathbf{w}_t - \\eta \\mathbf{p}_t), f(\\mathbf{w}_t), f(\\mathbf{w}_t + \\eta \\mathbf{p}_t )\\}\n",
        "\\end{equation}\n",
        "\n",
        "In words we pick the next iterate to be the point with lowest loss out of the three trail points.\n",
        "\n",
        "In the coodinate descent optimiser $\\mathbf{p}_t$ is sampled from $\\{\\mathbf{e}_1, \\mathbf{e}_2, \\dots, \\mathbf{e}_d\\}$ with equal probability where $\\mathbf{e}_i$ is the $i^{th}$ unit vertor.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rUuwPKIH0wNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 11** Implement the a gradient free coodinate descent optimiser and run for 1000 steps, save the loss value after each step in the list 'coord_dec_losses'."
      ],
      "metadata": {
        "id": "LYisvxySMiZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.zeros(M+1)\n",
        "\n",
        "coord_dec_losses = []\n",
        "coord_dec_losses.append(MSE_loss(X, y, w))\n",
        "\n",
        "number_of_iteratons = 1000\n",
        "eta = 0.1\n",
        "\n",
        "for iter in range(number_of_iteratons):\n",
        "  # ----------------------------\n",
        "  # Your code here\n",
        "\n",
        "\n",
        "  # --------------------------\n",
        "  loss = MSE_loss(X, y, w)\n",
        "  coord_dec_losses.append(loss)\n",
        "  eta *= 0.999\n",
        "  if iter % 100 == 99:\n",
        "    print(loss)\n",
        "\n",
        "plt.plot(np.arange(len(second_order_losses)),second_order_losses, 'black')\n",
        "plt.plot(np.arange(len(gd_losses)),gd_losses, 'red', label='gd')\n",
        "plt.plot(np.arange(len(line_search_losses)),line_search_losses, 'green')\n",
        "plt.plot(np.arange(len(gd_with_momenutm_losses)),gd_with_momenutm_losses, 'blue', label='gd_with_momentum')\n",
        "plt.plot(np.arange(len(gd_with_nesterov_momenutm)),gd_with_nesterov_momenutm, 'yellow', label='gd_with_momentum')\n",
        "plt.plot(np.arange(len(coord_dec_losses)),coord_dec_losses, 'purple')"
      ],
      "metadata": {
        "id": "ALR2i6Xh6vne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optional - Question 12** Implement a gradient free optimiser that instead selects $\\mathbf{p}$ uniformly from the unit hyper-sphere of dimention $d=$ (M+1) and run it for 1000 steps, save the loss value after each step in the list 'coord_dec_losses'."
      ],
      "metadata": {
        "id": "0CdPm3Dz_Jeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.zeros(M+1)\n",
        "\n",
        "grad_free_losses = []\n",
        "grad_free_losses.append(MSE_loss(X, y, w))\n",
        "\n",
        "number_of_iteratons = 1000\n",
        "eta = 0.1\n",
        "\n",
        "for iter in range(number_of_iteratons):\n",
        "  # ----------------------------\n",
        "  # Your code here\n",
        "\n",
        "  # --------------------------\n",
        "  loss = MSE_loss(X, y, w)\n",
        "  grad_free_losses.append(loss)\n",
        "  eta *= 0.999\n",
        "  if iter % 100 == 99:\n",
        "    print(loss)\n",
        "\n",
        "plt.plot(np.arange(len(second_order_losses)),second_order_losses, 'black')\n",
        "plt.plot(np.arange(len(gd_losses)),gd_losses, 'red', label='gd')\n",
        "plt.plot(np.arange(len(line_search_losses)),line_search_losses, 'green')\n",
        "plt.plot(np.arange(len(gd_with_momenutm_losses)),gd_with_momenutm_losses, 'blue', label='gd_with_momentum')\n",
        "plt.plot(np.arange(len(gd_with_nesterov_momenutm)),gd_with_nesterov_momenutm, 'yellow', label='gd_with_momentum')\n",
        "plt.plot(np.arange(len(coord_dec_losses)),coord_dec_losses, 'purple')\n",
        "plt.plot(np.arange(len(grad_free_losses)),grad_free_losses, 'orange')"
      ],
      "metadata": {
        "id": "bZxK9WM9_KSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell if you want to visualise a final model\n",
        "yhat = X@w\n",
        "plt.plot(x,y,'o', x, yhat, 'red')\n",
        "\n",
        "# plot the true function\n",
        "plt.plot(np.linspace(-1,1,50), np.sin(2*pi*.5*np.linspace(-1,1,50)), 'black')"
      ],
      "metadata": {
        "id": "lqAccInsWexq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}